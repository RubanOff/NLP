# Dynamic Memory Architectures for Personalized LLM Agents (Memory Personalisation Demo)

Прототип и мини-бенчмарк для сравнения подходов **без памяти**, **history**, **RAG** и гибридной архитектуры **Profile+RAG** для персонализированных LLM-агентов.

Идея проекта: стандартный RAG хорошо «вспоминает», но плохо **обновляет** противоречивые факты (stale memory). Мы добавляем **структурированный профиль** (актуальное состояние пользователя) + **эпизодическую память** (векторный стор), а также **guardrails** против записи PII.

---

## Что внутри

- `memory_personalisation_demo.ipynb` — основной ноутбук с реализацией и экспериментами.
- `personas.json` — 3 персоны (тон/формат/ограничения).
- `scenarios.json` — 10 сценариев (в т.ч. обновления, приватность, формат).
- `report_ru.tex` — русскоязычный отчёт (LaTeX).
- `lit.bib` — библиография для отчёта.
- `profile_rag_architecture_*.png` — схема архитектуры (рисунок для отчёта).
- `metrics_by_variant.png` — график средних метрик по архитектурам.

> Если у вас репозиторий содержит другой набор файлов/папок — адаптируйте пути в README под вашу структуру.

---

## Архитектуры

### 1) Baseline (stateless)
Никакой долговременной памяти: ответ только по текущему запросу.

### 2) History (full context)
Подсовываем модели историю диалога в контекст (в пределах окна). Минусы:
- дорого по токенам;
- PII остаётся в истории;
- нет явного «состояния пользователя».

### 3) Standard RAG
Сохраняем сообщения/факты в векторном хранилище и достаём top-k релевантных чанков. Минус:
- противоречивые факты часто достаются вместе (stale memory).

### 4) Profile+RAG (ours)
Разделяем память на:
- **Structured Profile** (`M_struct`) — JSON/Pydantic, актуальные ограничения/стиль (перезапись при обновлениях).
- **Episodic Vector Store** (`M_vec`) — ChromaDB для «воспоминаний».

Пайплайн (упрощённо):

1. `Memory Controller` (LLM-extractor) -> `Δprofile` + `facts`
2. `Merge(profile, Δprofile)` (обновления перезаписывают старое)
3. `Privacy Filter` (regex/Luhn) блокирует PII из записи в `M_vec`
4. `Retrieve(top-k)` из `M_vec` по текущему запросу
5. `Build system prompt` из профиля + retrieved memories
6. Генерация ответа

---

## Метрики (LLM-as-a-Judge)

Оценка проводится через отдельный «судью» (LLM-as-a-Judge), который по рубрике (JSON) выставляет:
- **Personalization score** (нормализованный/или 1–5)
- **Pref match** (соблюдение статических ограничений)
- **Update handling** (приоритет последних обновлений)
- **Stale memory avoidance** (не использовать устаревшее)
- **Privacy safety** (не записывать/не хранить PII)

---

## Быстрый старт

### 1) Зависимости
Рекомендуется Python 3.10+.

Примерно что нужно:
- `jupyter`
- `langchain`, `langchain-openai`
- `chromadb`, `langchain-chroma`
- `pydantic`
- `numpy`, `pandas`
- `matplotlib`

Установите зависимости любым удобным способом (pip/poetry/conda).

### 2) Переменные окружения
Для OpenAI-совместимых вызовов обычно требуется ключ:

```bash
export OPENAI_API_KEY="..."

